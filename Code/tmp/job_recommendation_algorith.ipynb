{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 17ms/step - loss: 7.3646 - accuracy: 0.0000e+00 - val_loss: 7.3715 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 7.2175 - accuracy: 0.0057 - val_loss: 7.4916 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 6.9972 - accuracy: 0.0076 - val_loss: 7.9686 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 6.6583 - accuracy: 0.0048 - val_loss: 8.8033 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 6.2418 - accuracy: 0.0171 - val_loss: 9.3086 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 5.7198 - accuracy: 0.0219 - val_loss: 10.0516 - val_accuracy: 0.0038\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 5.0669 - accuracy: 0.0676 - val_loss: 10.8630 - val_accuracy: 0.0038\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 4.3533 - accuracy: 0.1524 - val_loss: 11.7342 - val_accuracy: 0.0076\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 3.6977 - accuracy: 0.2352 - val_loss: 12.5319 - val_accuracy: 0.0038\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 3.1884 - accuracy: 0.3038 - val_loss: 13.0310 - val_accuracy: 0.0038\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 2.8257 - accuracy: 0.3333 - val_loss: 13.3363 - val_accuracy: 0.0038\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 2.4977 - accuracy: 0.4038 - val_loss: 13.7603 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 2.1785 - accuracy: 0.4552 - val_loss: 14.1860 - val_accuracy: 0.0038\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 2.0221 - accuracy: 0.5057 - val_loss: 14.5002 - val_accuracy: 0.0038\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.8677 - accuracy: 0.5229 - val_loss: 14.8960 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.7197 - accuracy: 0.5590 - val_loss: 15.2965 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.6278 - accuracy: 0.5562 - val_loss: 15.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 1.4848 - accuracy: 0.6190 - val_loss: 15.8862 - val_accuracy: 0.0038\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.4010 - accuracy: 0.6238 - val_loss: 16.1401 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.2658 - accuracy: 0.6514 - val_loss: 16.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1983 - accuracy: 0.6705 - val_loss: 16.7380 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.1135 - accuracy: 0.6981 - val_loss: 16.9791 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 1.0903 - accuracy: 0.7038 - val_loss: 17.1923 - val_accuracy: 0.0038\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 1.0436 - accuracy: 0.6895 - val_loss: 17.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.9540 - accuracy: 0.7276 - val_loss: 17.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.9953 - accuracy: 0.7314 - val_loss: 17.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.9342 - accuracy: 0.7333 - val_loss: 18.0580 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.8608 - accuracy: 0.7571 - val_loss: 18.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.8229 - accuracy: 0.7667 - val_loss: 18.5428 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.8515 - accuracy: 0.7495 - val_loss: 18.6190 - val_accuracy: 0.0038\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.8455 - accuracy: 0.7552 - val_loss: 18.6867 - val_accuracy: 0.0038\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.7586 - accuracy: 0.7752 - val_loss: 18.8432 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.7350 - accuracy: 0.7867 - val_loss: 19.0428 - val_accuracy: 0.0038\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.8095 - val_loss: 19.2754 - val_accuracy: 0.0038\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.6565 - accuracy: 0.8010 - val_loss: 19.4064 - val_accuracy: 0.0076\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6528 - accuracy: 0.8219 - val_loss: 19.5289 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.6623 - accuracy: 0.8114 - val_loss: 19.6561 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.6109 - accuracy: 0.8086 - val_loss: 19.7476 - val_accuracy: 0.0038\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6316 - accuracy: 0.8181 - val_loss: 19.8610 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5563 - accuracy: 0.8390 - val_loss: 19.9614 - val_accuracy: 0.0038\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5892 - accuracy: 0.8219 - val_loss: 20.0315 - val_accuracy: 0.0038\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5919 - accuracy: 0.8238 - val_loss: 20.2116 - val_accuracy: 0.0038\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5394 - accuracy: 0.8248 - val_loss: 20.4185 - val_accuracy: 0.0076\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5103 - accuracy: 0.8543 - val_loss: 20.6289 - val_accuracy: 0.0076\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.5089 - accuracy: 0.8495 - val_loss: 20.7440 - val_accuracy: 0.0038\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4972 - accuracy: 0.8429 - val_loss: 20.7741 - val_accuracy: 0.0038\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4912 - accuracy: 0.8505 - val_loss: 20.8843 - val_accuracy: 0.0038\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4663 - accuracy: 0.8486 - val_loss: 21.0713 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4341 - accuracy: 0.8686 - val_loss: 21.1622 - val_accuracy: 0.0038\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4287 - accuracy: 0.8676 - val_loss: 21.3727 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4202 - accuracy: 0.8781 - val_loss: 21.4704 - val_accuracy: 0.0038\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4157 - accuracy: 0.8733 - val_loss: 21.5483 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4408 - accuracy: 0.8600 - val_loss: 21.5861 - val_accuracy: 0.0038\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4210 - accuracy: 0.8733 - val_loss: 21.7179 - val_accuracy: 0.0114\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8752 - val_loss: 21.8156 - val_accuracy: 0.0038\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3862 - accuracy: 0.8829 - val_loss: 21.8543 - val_accuracy: 0.0114\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3798 - accuracy: 0.8743 - val_loss: 21.9438 - val_accuracy: 0.0038\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3665 - accuracy: 0.8981 - val_loss: 22.1229 - val_accuracy: 0.0076\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3706 - accuracy: 0.8829 - val_loss: 22.2076 - val_accuracy: 0.0076\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3441 - accuracy: 0.9000 - val_loss: 22.3225 - val_accuracy: 0.0076\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 0.8981 - val_loss: 22.4410 - val_accuracy: 0.0076\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.3238 - accuracy: 0.9038 - val_loss: 22.5400 - val_accuracy: 0.0038\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3383 - accuracy: 0.8914 - val_loss: 22.6132 - val_accuracy: 0.0076\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3435 - accuracy: 0.8914 - val_loss: 22.7427 - val_accuracy: 0.0076\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3045 - accuracy: 0.9038 - val_loss: 22.8916 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2971 - accuracy: 0.9048 - val_loss: 22.9220 - val_accuracy: 0.0038\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2810 - accuracy: 0.9171 - val_loss: 23.0635 - val_accuracy: 0.0038\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2944 - accuracy: 0.9010 - val_loss: 23.2063 - val_accuracy: 0.0038\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3205 - accuracy: 0.8990 - val_loss: 23.3067 - val_accuracy: 0.0038\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2922 - accuracy: 0.9057 - val_loss: 23.3646 - val_accuracy: 0.0038\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2422 - accuracy: 0.9238 - val_loss: 23.4706 - val_accuracy: 0.0038\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2553 - accuracy: 0.9152 - val_loss: 23.5949 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3043 - accuracy: 0.8981 - val_loss: 23.7060 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2660 - accuracy: 0.9210 - val_loss: 23.6899 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2638 - accuracy: 0.9190 - val_loss: 23.7415 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2418 - accuracy: 0.9248 - val_loss: 23.7825 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2389 - accuracy: 0.9362 - val_loss: 23.8780 - val_accuracy: 0.0038\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2047 - accuracy: 0.9410 - val_loss: 24.0553 - val_accuracy: 0.0038\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2503 - accuracy: 0.9238 - val_loss: 24.1486 - val_accuracy: 0.0038\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2544 - accuracy: 0.9200 - val_loss: 24.1429 - val_accuracy: 0.0038\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2555 - accuracy: 0.9181 - val_loss: 24.1821 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2166 - accuracy: 0.9333 - val_loss: 24.2842 - val_accuracy: 0.0076\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2533 - accuracy: 0.9181 - val_loss: 24.3847 - val_accuracy: 0.0038\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2303 - accuracy: 0.9248 - val_loss: 24.4700 - val_accuracy: 0.0076\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2352 - accuracy: 0.9257 - val_loss: 24.5248 - val_accuracy: 0.0076\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2151 - accuracy: 0.9248 - val_loss: 24.5256 - val_accuracy: 0.0076\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2035 - accuracy: 0.9381 - val_loss: 24.6107 - val_accuracy: 0.0038\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2282 - accuracy: 0.9248 - val_loss: 24.6728 - val_accuracy: 0.0038\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2239 - accuracy: 0.9295 - val_loss: 24.7377 - val_accuracy: 0.0038\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2005 - accuracy: 0.9324 - val_loss: 24.8340 - val_accuracy: 0.0038\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2157 - accuracy: 0.9295 - val_loss: 24.9158 - val_accuracy: 0.0038\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1832 - accuracy: 0.9438 - val_loss: 24.9318 - val_accuracy: 0.0038\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2355 - accuracy: 0.9238 - val_loss: 25.0205 - val_accuracy: 0.0038\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1711 - accuracy: 0.9505 - val_loss: 25.1021 - val_accuracy: 0.0038\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2090 - accuracy: 0.9410 - val_loss: 25.2305 - val_accuracy: 0.0038\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1871 - accuracy: 0.9400 - val_loss: 25.3083 - val_accuracy: 0.0038\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1947 - accuracy: 0.9362 - val_loss: 25.4087 - val_accuracy: 0.0038\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1569 - accuracy: 0.9467 - val_loss: 25.6144 - val_accuracy: 0.0038\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1722 - accuracy: 0.9476 - val_loss: 25.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1950 - accuracy: 0.9429 - val_loss: 25.8232 - val_accuracy: 0.0038\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 25.1652 - accuracy: 0.0061\n",
      "Test Accuracy: 0.01\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Recommended Jobs:\n",
      "- FORMS DESIGNER in the field of DESIGNER\n",
      "- MARKETER / ADMINISTRATOR in the field of HEALTHCARE\n",
      "- DIGITAL STRATEGY MANAGER in the field of DIGITAL-MEDIA\n",
      "- PRESIDENT in the field of AGRICULTURE\n",
      "- CHIEF SYSTEM ARCHITECT in the field of DIGITAL-MEDIA\n",
      "Model saved to ..\\Code\\Pickles\\job_recommendation_algorith.h5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "csv_path = os.path.join('..', 'Data', 'Diagested_data', 'Numeric_resume_data.csv')\n",
    "data = pd.read_csv(csv_path)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define trait columns\n",
    "trait_columns = [\n",
    "    'Leadership', 'Communication', 'Teamwork', 'Problem Solving', 'Creativity',\n",
    "    'Adaptability', 'Work Ethic', 'Time Management', 'Interpersonal Skills', \n",
    "    'Attention to Detail', 'Initiative', 'Analytical Thinking', 'Emotional Intelligence', \n",
    "    'Integrity', 'Resilience', 'Cultural Awareness', 'Programming Languages', \n",
    "    'Technical Skills', 'Office Tools'\n",
    "]\n",
    "\n",
    "# Convert job titles to numerical labels\n",
    "job_titles = df['Job Title'].unique()\n",
    "job_domains = df[['Job Title', 'Domain']].drop_duplicates().set_index('Job Title')['Domain'].to_dict()\n",
    "job_title_to_index = {title: idx for idx, title in enumerate(job_titles)}\n",
    "index_to_job_title = {idx: title for title, idx in job_title_to_index.items()}\n",
    "df['Job Label'] = df['Job Title'].map(job_title_to_index)\n",
    "\n",
    "# Prepare feature and target arrays\n",
    "X = df[trait_columns].values\n",
    "y = df['Job Label'].values\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(job_titles)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y)  # Fit on the entire set of labels to ensure it has all classes\n",
    "y_train_onehot = lb.transform(y_train)\n",
    "y_test_onehot = lb.transform(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(512, input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dropout(0.5),\n",
    "    Dense(256),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_onehot, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test_onehot)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Function to recommend top 5 jobs with their domains\n",
    "def recommend_jobs(trait_scores, top_n=5):\n",
    "    # Predict job probabilities for the given trait scores\n",
    "    trait_scores = np.array(trait_scores).reshape(1, -1)\n",
    "    trait_scores_scaled = scaler.transform(trait_scores)  # Scale the input trait scores\n",
    "    predictions = model.predict(trait_scores_scaled)\n",
    "    \n",
    "    # Get the indices of the top N probabilities\n",
    "    top_indices = np.argsort(predictions[0])[-top_n:][::-1]\n",
    "    \n",
    "    # Map indices back to job titles and domains\n",
    "    top_jobs = [(index_to_job_title[idx], job_domains[index_to_job_title[idx]]) for idx in top_indices]\n",
    "    return top_jobs\n",
    "\n",
    "# Example trait scores\n",
    "trait_scores = [2, 1, 3, 3, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 1, 0]\n",
    "\n",
    "# Recommend top 5 jobs\n",
    "recommended_jobs = recommend_jobs(trait_scores)\n",
    "print('Recommended Jobs:')\n",
    "for job, domain in recommended_jobs:\n",
    "    print(f'- {job} in the field of {domain}')\n",
    "\n",
    "# Save the model to a file\n",
    "model_save_path = os.path.join('..', 'Code', 'Pickles', 'job_recommendation_algorith.h5')\n",
    "model.save(model_save_path)\n",
    "print(f'Model saved to {model_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
